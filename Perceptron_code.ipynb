{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnK74ZcrWZFje5v2cv6zmx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Perceptron_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPG-wC8PXmX",
        "outputId": "be135177-0ea5-4e31-fb9d-9363891b470c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Destination: City\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "destinations = {\n",
        "    'Beach': np.array([0, 1, 0]),  # Features: [Scenic Beauty, Water Activities, Nightlife]\n",
        "    'Mountain': np.array([1, 0, 0]),  # Features: [Scenic Beauty, Hiking, Adventure Sports]\n",
        "    'City': np.array([0, 0, 1])  # Features: [Shopping, Museums, Nightlife]\n",
        "}\n",
        "\n",
        "# Define the weights for each feature\n",
        "weights = np.array([0.3, 0.3, 0.2])\n",
        "\n",
        "def perceptron(features):\n",
        "\n",
        "    activation = np.dot(features, weights)\n",
        "\n",
        "    if activation >= 0.5:\n",
        "        return 'Mountain'\n",
        "    elif activation <= -0.5:\n",
        "        return 'Beach'\n",
        "    else:\n",
        "        return 'City'\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "tourist_features = np.array([0.8, 0.2, 0.5])  # Example features: [Scenic Beauty, Water Activities, Nightlife]\n",
        "predicted_destination = perceptron(tourist_features)\n",
        "print(\"Predicted Destination:\", predicted_destination)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the features and labels (crop yields)\n",
        "# Features: [Temperature, Rainfall, Soil Quality]\n",
        "# Labels: Crop Yields (in tons)\n",
        "# Example data (can be replaced with actual data)\n",
        "X_train = np.array([[25, 100, 7],\n",
        "                    [30, 80, 6],\n",
        "                    [20, 120, 8],\n",
        "                    [22, 90, 5],\n",
        "                    [28, 110, 7]])\n",
        "\n",
        "y_train = np.array([5, 6, 4, 4.5, 5.5])\n",
        "\n",
        "# Feature Scaling\n",
        "X_train_scaled = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
        "\n",
        "# Define the perceptron model\n",
        "class Perceptron:\n",
        "    def __init__(self):\n",
        "        self.weights = np.random.rand(3)  # Initialize weights randomly\n",
        "        self.bias = np.random.rand(1)     # Initialize bias randomly\n",
        "    def predict(self, features):\n",
        "        # Calculate the weighted sum of inputs and add bias\n",
        "        activation = np.dot(features, self.weights) + self.bias\n",
        "        return activation\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(len(X_train)):\n",
        "                # Predict output\n",
        "                prediction = self.predict(X_train[i])\n",
        "\n",
        "                # Compute error\n",
        "                error = y_train[i] - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += learning_rate * error * X_train[i]\n",
        "                self.bias += learning_rate * error\n",
        "\n",
        "# Instantiate the Perceptron model\n",
        "model = Perceptron()\n",
        "\n",
        "# Train the model using X_train_scaled and y_train\n",
        "model.train(X_train_scaled, y_train)\n",
        "\n",
        "# Test the model with new data\n",
        "new_data = np.array([[27, 95, 6.5]])  # New feature values for prediction\n",
        "new_data_scaled = (new_data - X_train.mean(axis=0)) / X_train.std(axis=0)  # Scale new data\n",
        "predicted_yield = model.predict(new_data_scaled)\n",
        "\n",
        "# Convert predicted_yield to a proper data type\n",
        "predicted_yield = predicted_yield.item()\n",
        "\n",
        "print(\"Predicted crop yield:\", predicted_yield)\n",
        "\n",
        "# Define crop names and their corresponding yield thresholds\n",
        "crop_mapping = {\n",
        "    'Crop A': 5,\n",
        "    'Crop B': 6,\n",
        "    'Crop C': 4,\n",
        "    'Crop D': 4.5,\n",
        "    'Crop E': 5.5\n",
        "}\n",
        "\n",
        "# Function to determine crop name based on predicted yield\n",
        "def get_predicted_crop(predicted_yield, crop_mapping):\n",
        "    for crop, threshold in crop_mapping.items():\n",
        "        if predicted_yield >= threshold:\n",
        "            return crop\n",
        "    return 'Unknown Crop'\n",
        "\n",
        "# Get the predicted crop name\n",
        "predicted_crop = get_predicted_crop(predicted_yield, crop_mapping)\n",
        "\n",
        "print(\"Predicted crop:\", predicted_crop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwhvRryyYGwH",
        "outputId": "633d2e8b-993a-43c6-e2fb-41c05ae1a47b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted crop yield: 5.356775249942851\n",
            "Predicted crop: Crop A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your dataset)\n",
        "X = np.array([[2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n",
        "y = np.array([0, 0, 1, 1, 1])  # Binary labels: 0 or 1\n",
        "\n",
        "# Define the perceptron model\n",
        "class Perceptron:\n",
        "    def __init__(self, num_features):  # Add the 'self' argument\n",
        "        self.weights = np.random.rand(num_features)  # Initialize weights randomly\n",
        "        self.bias = np.random.rand(1)                # Initialize bias randomly\n",
        "\n",
        "    def predict(self, features):\n",
        "        # Calculate the weighted sum of inputs and add bias\n",
        "        activation = np.dot(features, self.weights) + self.bias\n",
        "        return 1 if activation >= 0 else 0  # Apply step function for binary classification\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(len(X_train)):\n",
        "                # Predict output\n",
        "                prediction = self.predict(X_train[i])\n",
        "\n",
        "                # Compute error\n",
        "                error = y_train[i] - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += learning_rate * error * X_train[i]\n",
        "                self.bias += learning_rate * error\n",
        "\n",
        "# Instantiate the Perceptron model\n",
        "model = Perceptron(num_features=X.shape[1])\n",
        "\n",
        "# Train the model\n",
        "model.train(X, y)\n",
        "\n",
        "new_data = np.array([[3, 4], [9, 10], [7, 8]])  # New data points for prediction\n",
        "predictions = [model.predict(data) for data in new_data]\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mDYkuDbipPQ",
        "outputId": "c7fef203-f3f1-41d2-eaaa-ee5edc7eab34"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0, 1, 1]\n"
          ]
        }
      ]
    }
  ]
}