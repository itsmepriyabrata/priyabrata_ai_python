{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq+lGT1X4gZhwMfrt/fzw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Deep_Learning_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inceptionNet"
      ],
      "metadata": {
        "id": "tHaZO-e0nA0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx4dRcLKkubu"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from keras.applications import InceptionV3\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_dir = 'path_to_your_train_directory'\n",
        "val_dir = 'path_to_your_validation_directory'\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint('inceptionnet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "model.load_weights('inceptionnet.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet"
      ],
      "metadata": {
        "id": "ZZbdT1_bnKGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from keras.applications import DenseNet121\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_dir = 'path_to_your_train_directory'\n",
        "val_dir = 'path_to_your_validation_directory'\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint('densenet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "model.load_weights('densenet.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "WI2hHyJqnM0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet"
      ],
      "metadata": {
        "id": "I96szDg9oUwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_dir = 'path_to_your_train_directory'\n",
        "val_dir = 'path_to_your_validation_directory'\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint('mobilenet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "model.load_weights('mobilenet.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "TvjF_fIqotVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet"
      ],
      "metadata": {
        "id": "_TOJhJ42pEEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from keras.applications import EfficientNetB0\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_dir = 'path_to_your_train_directory'\n",
        "val_dir = 'path_to_your_validation_directory'\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint('efficientnet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "model.load_weights('efficientnet.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "xV2MLbcXpBNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capsule networks"
      ],
      "metadata": {
        "id": "PnUrhkNasGJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from keras import layers, models, optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "train_dir = 'path_to_your_train_directory'\n",
        "val_dir = 'path_to_your_validation_directory'\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    output = layers.Reshape(target_shape=[-1, dim_capsule])(output)\n",
        "    return layers.Lambda(lambda x: layers.K.stack(x, axis=-1))(output)\n",
        "\n",
        "def CapsuleLayer(num_capsule, dim_capsule, routings):\n",
        "    def func(input_capsule):\n",
        "        output = layers.Dense(num_capsule * dim_capsule, activation='relu')(input_capsule)\n",
        "        output = layers.Reshape([num_capsule, dim_capsule])(output)\n",
        "        output = layers.Lambda(lambda x: layers.K.l2_normalize(x, -1))(output)\n",
        "        return layers.Capsule(num_capsule=num_capsule, dim_capsule=dim_capsule, routings=routings, name='caps')(output)\n",
        "    return func\n",
        "\n",
        "def CapsuleNet(input_shape, n_class, routings):\n",
        "    x = layers.Input(shape=input_shape)\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
        "    out_caps = layers.Flatten()(digitcaps)\n",
        "    model = models.Model(x, out_caps)\n",
        "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss='mse', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "model = CapsuleNet(input_shape=(28, 28, 1), n_class=8, routings=3)\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "-omrSEEgsFvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}