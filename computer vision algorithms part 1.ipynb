{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi/ma9Wu8YyYPLTPBntkeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/computer%20vision%20algorithms%20part%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edge detection algorithms"
      ],
      "metadata": {
        "id": "qIe9hSTb7Agb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_gQiY_q6olx",
        "outputId": "2d2f691d-4c7b-4f01-ec41-7403ea024550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if image is None:\n",
        "    print(f\"Error: Unable to load image at {image_path}\")\n",
        "    exit()\n",
        "\n",
        "# Sobel Edge Detection\n",
        "def sobel_edge_detection(image):\n",
        "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
        "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
        "    sobel_combined = cv2.magnitude(sobel_x, sobel_y)\n",
        "    return sobel_x, sobel_y, sobel_combined\n",
        "\n",
        "# Laplacian Edge Detection\n",
        "def laplacian_edge_detection(image):\n",
        "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
        "    return laplacian\n",
        "\n",
        "# Canny Edge Detection\n",
        "def canny_edge_detection(image, low_threshold, high_threshold):\n",
        "    canny = cv2.Canny(image, low_threshold, high_threshold)\n",
        "    return canny\n",
        "\n",
        "# Apply edge detection algorithms\n",
        "sobel_x, sobel_y, sobel_combined = sobel_edge_detection(image)\n",
        "laplacian = laplacian_edge_detection(image)\n",
        "canny = canny_edge_detection(image, 100, 200)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.title('Sobel X')\n",
        "plt.imshow(sobel_x, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.title('Sobel Y')\n",
        "plt.imshow(sobel_y, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.title('Sobel Combined')\n",
        "plt.imshow(sobel_combined, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.title('Laplacian')\n",
        "plt.imshow(laplacian, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.title('Canny')\n",
        "plt.imshow(canny, cmap='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0ZM8IlL47l8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HoughTransform"
      ],
      "metadata": {
        "id": "WojXF2a67qMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found at the path: {image_path}\")\n",
        "    return image\n",
        "\n",
        "def detect_lines(image, canny_threshold1=50, canny_threshold2=150, hough_threshold=100):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, canny_threshold1, canny_threshold2)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, hough_threshold)\n",
        "    if lines is not None:\n",
        "        for rho, theta in lines[:, 0]:\n",
        "            a = np.cos(theta)\n",
        "            b = np.sin(theta)\n",
        "            x0 = a * rho\n",
        "            y0 = b * rho\n",
        "            x1 = int(x0 + 1000 * (-b))\n",
        "            y1 = int(y0 + 1000 * (a))\n",
        "            x2 = int(x0 - 1000 * (-b))\n",
        "            y2 = int(y0 - 1000 * (a))\n",
        "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    return image\n",
        "\n",
        "def detect_circles(image, dp=1.2, min_dist=100, param1=50, param2=30, min_radius=0, max_radius=0):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.medianBlur(gray, 5)\n",
        "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp, min_dist,\n",
        "                               param1=param1, param2=param2,\n",
        "                               minRadius=min_radius, maxRadius=max_radius)\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "        for (x, y, r) in circles:\n",
        "            cv2.circle(image, (x, y), r, (0, 255, 0), 4)\n",
        "            cv2.rectangle(image, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
        "    return image\n",
        "\n",
        "def display_image(image, title='Image'):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
        "    image = load_image(image_path)\n",
        "\n",
        "    line_detected_image = detect_lines(image.copy())\n",
        "    display_image(line_detected_image, 'Hough Line Transform')\n",
        "\n",
        "    circle_detected_image = detect_circles(image.copy())\n",
        "    display_image(circle_detected_image, 'Hough Circle Transform')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "eiHb4mhK7p8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPtical flow"
      ],
      "metadata": {
        "id": "m7SbRgEK8Eg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def lucas_kanade_optical_flow(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    lk_params = dict(winSize=(15, 15),\n",
        "                     maxLevel=2,\n",
        "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7))\n",
        "\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "        good_new = p1[st == 1]\n",
        "        good_old = p0[st == 1]\n",
        "\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)\n",
        "            frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
        "\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        cv2.imshow('Lucas-Kanade Optical Flow', img)\n",
        "        if cv2.waitKey(30) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "        old_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def farneback_optical_flow(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame1 = cap.read()\n",
        "    prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    hsv_mask = np.zeros_like(frame1)\n",
        "    hsv_mask[..., 1] = 255\n",
        "\n",
        "    while True:\n",
        "        ret, frame2 = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        next_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        flow = cv2.calcOpticalFlowFarneback(prvs, next_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "        hsv_mask[..., 0] = angle * 180 / np.pi / 2\n",
        "        hsv_mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        bgr = cv2.cvtColor(hsv_mask, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        cv2.imshow('Farneback Optical Flow', bgr)\n",
        "        if cv2.waitKey(30) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "        prvs = next_frame\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def main():\n",
        "    video_path = 'path_to_your_video.mp4'  # Replace with your video path\n",
        "\n",
        "    print(\"Running Lucas-Kanade Optical Flow\")\n",
        "    lucas_kanade_optical_flow(video_path)\n",
        "\n",
        "    print(\"Running Farneback Optical Flow\")\n",
        "    farneback_optical_flow(video_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "oRAI6M558EO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "scale invariant feature"
      ],
      "metadata": {
        "id": "ic0lZsw78y9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found at the path: {image_path}\")\n",
        "    return image\n",
        "\n",
        "def sift_feature_detection(image):\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def draw_keypoints(image, keypoints):\n",
        "    image_with_keypoints = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    return image_with_keypoints\n",
        "\n",
        "def match_features(descriptors1, descriptors2):\n",
        "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "    return matches\n",
        "\n",
        "def draw_matches(image1, keypoints1, image2, keypoints2, matches):\n",
        "    matched_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "    return matched_image\n",
        "\n",
        "def display_image(image, title='Image'):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    image_path1 = 'path_to_your_image1.jpg'  # Replace with your first image path\n",
        "    image_path2 = 'path_to_your_image2.jpg'  # Replace with your second image path\n",
        "\n",
        "    image1 = load_image(image_path1)\n",
        "    image2 = load_image(image_path2)\n",
        "\n",
        "    keypoints1, descriptors1 = sift_feature_detection(image1)\n",
        "    keypoints2, descriptors2 = sift_feature_detection(image2)\n",
        "\n",
        "    image1_with_keypoints = draw_keypoints(image1, keypoints1)\n",
        "    image2_with_keypoints = draw_keypoints(image2, keypoints2)\n",
        "\n",
        "    display_image(image1_with_keypoints, 'Image 1 with SIFT Keypoints')\n",
        "    display_image(image2_with_keypoints, 'Image 2 with SIFT Keypoints')\n",
        "\n",
        "    matches = match_features(descriptors1, descriptors2)\n",
        "\n",
        "    matched_image = draw_matches(image1, keypoints1, image2, keypoints2, matches)\n",
        "\n",
        "    display_image(matched_image, 'Matched Features between Images')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "2zWiLt8b8zO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}