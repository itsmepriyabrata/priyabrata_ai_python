{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnLJfV4LXfPFJ/H/jYBTKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Optimization_part_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BFGS(broyden fletcher goldfarb shanno)"
      ],
      "metadata": {
        "id": "n8H-prU-ZmYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def objective_function(x):\n",
        "  \"\"\"Replace this with your actual objective function to be minimized.\n",
        "\n",
        "  This example uses a simple sphere function.\n",
        "  \"\"\"\n",
        "  return x[0]**2 + x[1]**2\n",
        "\n",
        "\n",
        "def gradient(x):\n",
        "  \"\"\"Calculates the gradient of the objective function.\n",
        "\n",
        "  This example calculates the gradient of the sphere function.\n",
        "  \"\"\"\n",
        "  return np.array([2*x[0], 2*x[1]])\n",
        "\n",
        "\n",
        "def bfgs(f, grad, x0, max_iter=100, tol=1e-6):\n",
        "  \"\"\"Implements the BFGS algorithm for optimization.\n",
        "\n",
        "  Args:\n",
        "      f: The objective function to minimize.\n",
        "      grad: The gradient function of the objective function.\n",
        "      x0: The initial guess for the solution.\n",
        "      max_iter: The maximum number of iterations (default: 100).\n",
        "      tol: The tolerance for convergence (default: 1e-6).\n",
        "\n",
        "  Returns:\n",
        "      x: The optimal solution found.\n",
        "      f_min: The minimum value of the objective function at the solution.\n",
        "  \"\"\"\n",
        "\n",
        "  x = x0\n",
        "  Hk = np.eye(len(x))\n",
        "  f_min = f(x)\n",
        "  iter_count = 0\n",
        "\n",
        "  while iter_count < max_iter and np.linalg.norm(grad(x)) > tol:\n",
        "    g = grad(x)\n",
        "\n",
        "    s = -Hk @ g\n",
        "\n",
        "    alpha = line_search(f, grad, x, s) # Pass the gradient function to line_search\n",
        "\n",
        "    x = x + alpha * s\n",
        "\n",
        "    g_new = grad(x)\n",
        "\n",
        "    y = g_new - g\n",
        "    s_T_y = np.dot(s.T, y)\n",
        "    if s_T_y > 0:\n",
        "      rho = 1.0 / s_T_y\n",
        "      sk = s\n",
        "      yk = y\n",
        "      Hk = Hk - np.outer(sk, sk.T) * rho + np.outer(yk, yk.T) * rho\n",
        "\n",
        "    iter_count += 1\n",
        "    f_min = min(f_min, f(x))\n",
        "\n",
        "  return x, f_min\n",
        "\n",
        "\n",
        "def line_search(f, grad, x, s, alpha=0.1, beta=0.5): # Add grad as a parameter\n",
        "  \"\"\"Performs a line search to find an appropriate step size.\n",
        "\n",
        "  Uses the Armijo line search rule.\n",
        "\n",
        "  Args:\n",
        "      f: The objective function.\n",
        "      grad: The gradient function. # Document the new parameter\n",
        "      x: The current position.\n",
        "      s: The search direction.\n",
        "      alpha: Initial step size (default: 0.1).\n",
        "      beta: Backtracking factor (default: 0.5).\n",
        "\n",
        "  Returns:\n",
        "      The step size that satisfies the Armijo line search rule.\n",
        "  \"\"\"\n",
        "  while f(x + alpha * s) > f(x) + alpha * beta * np.dot(grad(x).T, s):\n",
        "    alpha *= beta\n",
        "  return alpha\n",
        "\n",
        "\n",
        "def main():\n",
        "  x0 = np.array([1.0, 2.0])\n",
        "\n",
        "  optimal_x, min_value = bfgs(objective_function, gradient, x0)\n",
        "\n",
        "  print(f\"Minimum found at: {optimal_x}\")\n",
        "  print(f\"Minimum value: {min_value}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkccCzMMe-Ah",
        "outputId": "66d27a98-edb8-438b-b362-fbc4899b4d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum found at: [0.8 1.6]\n",
            "Minimum value: 3.2000000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L-BFGS(limited memory BFGS)"
      ],
      "metadata": {
        "id": "08gujh0cZ-HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # Import NumPy and give it the alias 'np'\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "def objective_function(x):\n",
        "  \"\"\"Replace this with your actual objective function to be minimized.\n",
        "\n",
        "  This example uses a simple sphere function.\n",
        "  \"\"\"\n",
        "  return x[0]**2 + x[1]**2\n",
        "\n",
        "\n",
        "def main():\n",
        "  initial_guess = np.array([1.0, 2.0])\n",
        "\n",
        "  result = minimize(objective_function, initial_guess, method='L-BFGS-B')\n",
        "\n",
        "  print(f\"Minimum found at: {result.x}\")\n",
        "  print(f\"Minimum value: {result.fun}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWR5EDIweIRO",
        "outputId": "8d22f087-bf1e-4772-ffcf-6fe9d29d9b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum found at: [3.88821852e-09 5.15555620e-09]\n",
            "Minimum value: 4.169800307197592e-17\n"
          ]
        }
      ]
    }
  ]
}