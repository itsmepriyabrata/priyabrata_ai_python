{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPnfh0cPwV26zhbJ6x5kU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Recommendation_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assosiate rule learning"
      ],
      "metadata": {
        "id": "K9mrD3pGvuu5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qesCUAwBvpLo",
        "outputId": "4d6f93f4-e755-47b5-ba85-71fe0adf5a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (3.7.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "transactions = [\n",
        "    ['milk', 'bread', 'butter'],\n",
        "    ['beer', 'bread'],\n",
        "    ['milk', 'bread', 'butter'],\n",
        "    ['beer', 'bread', 'butter'],\n",
        "    ['milk', 'bread'],\n",
        "    ['beer', 'bread']\n",
        "]\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-OyR0nSwvE1",
        "outputId": "e7b5bfd8-a642-4ea9-e635-7a43eba52c3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "   support         itemsets\n",
            "0      0.5           (beer)\n",
            "1      1.0          (bread)\n",
            "2      0.5         (butter)\n",
            "3      0.5           (milk)\n",
            "4      0.5    (bread, beer)\n",
            "5      0.5  (bread, butter)\n",
            "6      0.5    (bread, milk)\n",
            "\n",
            "Association Rules:\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0     (bread)      (beer)                 1.0                 0.5      0.5   \n",
            "1      (beer)     (bread)                 0.5                 1.0      0.5   \n",
            "2     (bread)    (butter)                 1.0                 0.5      0.5   \n",
            "3    (butter)     (bread)                 0.5                 1.0      0.5   \n",
            "4     (bread)      (milk)                 1.0                 0.5      0.5   \n",
            "5      (milk)     (bread)                 0.5                 1.0      0.5   \n",
            "\n",
            "   confidence  lift  leverage  conviction  zhangs_metric  \n",
            "0         0.5   1.0       0.0         1.0            0.0  \n",
            "1         1.0   1.0       0.0         inf            0.0  \n",
            "2         0.5   1.0       0.0         1.0            0.0  \n",
            "3         1.0   1.0       0.0         inf            0.0  \n",
            "4         0.5   1.0       0.0         1.0            0.0  \n",
            "5         1.0   1.0       0.0         inf            0.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Collaborative filtering"
      ],
      "metadata": {
        "id": "NyfF35qowzbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sax_E9uOw56L",
        "outputId": "89c0d4d9-a1b8-4f8a-d392-d50b85c958a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Dummy dataset\n",
        "class NCFDataset(Dataset):\n",
        "    def __init__(self, user_item_matrix):\n",
        "        self.user_item_matrix = user_item_matrix\n",
        "        self.users, self.items = np.nonzero(user_item_matrix)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.users[idx]\n",
        "        item = self.items[idx]\n",
        "        rating = self.user_item_matrix[user, item]\n",
        "        return user, item, rating\n",
        "\n",
        "# NCF Model\n",
        "class NCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, latent_dim):\n",
        "        super(NCF, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(latent_dim * 2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        user_embedding = self.user_embedding(user)\n",
        "        item_embedding = self.item_embedding(item)\n",
        "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Sample data\n",
        "num_users = 100\n",
        "num_items = 50\n",
        "latent_dim = 8\n",
        "\n",
        "user_item_matrix = np.random.randint(2, size=(num_users, num_items))\n",
        "\n",
        "dataset = NCFDataset(user_item_matrix)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "model = NCF(num_users, num_items, latent_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for user, item, rating in dataloader:\n",
        "        user = user.long()\n",
        "        item = item.long()\n",
        "        rating = rating.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(user, item).squeeze()\n",
        "        loss = criterion(output, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFm33gQUxs0Z",
        "outputId": "f28c664a-44e0-4845-ebf2-94c0f15c6fc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.17278393543077797\n",
            "Epoch 2/10, Loss: 0.013519892439576266\n",
            "Epoch 3/10, Loss: 0.007267190612074506\n",
            "Epoch 4/10, Loss: 0.004201037106339973\n",
            "Epoch 5/10, Loss: 0.002694900149827281\n",
            "Epoch 6/10, Loss: 0.001794071225567332\n",
            "Epoch 7/10, Loss: 0.0012660618352739116\n",
            "Epoch 8/10, Loss: 0.0009675088480020626\n",
            "Epoch 9/10, Loss: 0.0007192134032692006\n",
            "Epoch 10/10, Loss: 0.0005837882267712038\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid recommendation systems"
      ],
      "metadata": {
        "id": "NEUOKToBzmmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn surprise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAnM1Bb_1Twb",
        "outputId": "07312525-cee7-4eff-9cd3-c70b4fc939f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357251 sha256=c9e93deaefaeebca27e0cbd0b8638910dc58bcd001548bf3046011647d986a50\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Load data\n",
        "ratings_data = {\n",
        "    'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
        "    'item_id': [101, 102, 103, 101, 102, 104, 103, 104, 105],\n",
        "    'rating': [5, 4, 3, 4, 5, 4, 3, 5, 4]\n",
        "}\n",
        "\n",
        "item_data = {\n",
        "    'item_id': [101, 102, 103, 104, 105],\n",
        "    'title': ['Item A', 'Item B', 'Item C', 'Item D', 'Item E'],\n",
        "    'description': ['A great item', 'An awesome item', 'A fantastic item', 'A superb item', 'A magnificent item']\n",
        "}\n",
        "\n",
        "ratings_df = pd.DataFrame(ratings_data)\n",
        "items_df = pd.DataFrame(item_data)\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(items_df['description'])\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "def hybrid_recommend(user_id, item_id, top_n=5):\n",
        "    collab_pred = algo.predict(user_id, item_id).est\n",
        "\n",
        "    item_idx = items_df[items_df['item_id'] == item_id].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[item_idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    content_based_recommendations = [i[0] for i in sim_scores[1:top_n+1]]\n",
        "\n",
        "    content_pred = items_df.iloc[content_based_recommendations].to_dict('records')\n",
        "\n",
        "    return {\n",
        "        'Collaborative Filtering Prediction': collab_pred,\n",
        "        'Content-Based Recommendations': content_pred\n",
        "    }\n",
        "\n",
        "user_id = 1\n",
        "item_id = 105\n",
        "\n",
        "recommendations = hybrid_recommend(user_id, item_id)\n",
        "print(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GwIajzP2GFk",
        "outputId": "8dcbd1fa-a461-4b5b-990f-110ae8fa637c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Collaborative Filtering Prediction': 3.7221028039785558, 'Content-Based Recommendations': [{'item_id': 101, 'title': 'Item A', 'description': 'A great item'}, {'item_id': 102, 'title': 'Item B', 'description': 'An awesome item'}, {'item_id': 103, 'title': 'Item C', 'description': 'A fantastic item'}, {'item_id': 104, 'title': 'Item D', 'description': 'A superb item'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}