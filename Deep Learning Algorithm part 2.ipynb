{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Deep%20Learning%20Algorithm%20part%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saOalu-fBgP6"
      },
      "source": [
        "Deep belief networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIP8EfM_Cejx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "\n",
        "# Define RBM class\n",
        "RBM = namedtuple(\"RBM\", [\"weights\", \"v_bias\", \"h_bias\"])\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_rbm(v_visible, learning_rate, epochs):\n",
        "  \"\"\"Trains a single RBM layer\"\"\"\n",
        "  # Initialize weights and biases with random values\n",
        "  num_visible = v_visible.shape[1]\n",
        "  num_hidden = ... # Define number of hidden units\n",
        "  weights = np.random.randn(num_visible, num_hidden)\n",
        "  v_bias = np.zeros(num_visible)\n",
        "  h_bias = np.zeros(num_hidden)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    return RBM(weights, v_bias, h_bias)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNro6AxXCoc1"
      },
      "source": [
        "Transformer networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxpm5aTBDSpz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, nhead, dim_feedforward):\n",
        "    super().__init__()\n",
        "    self.self_attn = nn.MultiheadAttention(d_model, nhead)\n",
        "    self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "    self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "    self.dropout = nn.Dropout(p=0.1)\n",
        "    self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "    self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    src = self.self_attn(src, src, src, attn_mask=src_mask)[0]\n",
        "    src = self.dropout(src)\n",
        "    src = self.layer_norm1(src + src)\n",
        "\n",
        "    src = self.linear2(self.dropout(self.linear1(src)))\n",
        "    src = self.layer_norm2(src + src)\n",
        "    return src\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, d_model, nhead, num_layers, dim_feedforward):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList([TransformerEncoderLayer(d_model, nhead, dim_feedforward) for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    for layer in self.layers:\n",
        "      src = layer(src, src_mask)\n",
        "    return src\n",
        "\n",
        "# Example usage (assuming preprocessed data)\n",
        "src = torch.rand(10, 5, 512)  # Batch size, sequence length, embedding size\n",
        "src_mask = torch.ones(10, 5, 5)  # Attention mask to prevent padding tokens from influencing attention\n",
        "\n",
        "transformer_encoder = TransformerEncoder(512, 8, 2, 2048)\n",
        "encoded_src = transformer_encoder(src, src_mask)\n",
        "\n",
        "print(encoded_src.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP0DxWePDYq-"
      },
      "source": [
        "U-net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHYRoetmFAvK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "def unet_model(input_size=(128, 128, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv5))\n",
        "    merge6 = layers.concatenate([conv4, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "    conv9 = layers.Conv2D(2, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Dummy data for demonstration\n",
        "X_train = np.random.rand(100, 128, 128, 1)\n",
        "Y_train = np.random.rand(100, 128, 128, 1)\n",
        "X_test = np.random.rand(20, 128, 128, 1)\n",
        "Y_test = np.random.rand(20, 128, 128, 1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "Y_train = Y_train / 255.0\n",
        "Y_test = Y_test / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                     width_shift_range=0.05,\n",
        "                     height_shift_range=0.05,\n",
        "                     shear_range=0.05,\n",
        "                     zoom_range=0.05,\n",
        "                     horizontal_flip=True,\n",
        "                     fill_mode='nearest')\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "seed = 1\n",
        "image_datagen.fit(X_train, augment=True, seed=seed)\n",
        "mask_datagen.fit(Y_train, augment=True, seed=seed)\n",
        "\n",
        "image_generator = image_datagen.flow(X_train, batch_size=32, seed=seed)\n",
        "mask_generator = mask_datagen.flow(Y_train, batch_size=32, seed=seed)\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=len(X_train) // 32, epochs=50)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYfcilAaFHpD"
      },
      "source": [
        "ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eeboD53FLJl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "def resnet_block(input_tensor, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\"\"\"\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride)(input_tensor)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    else:\n",
        "        shortcut = input_tensor\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', strides=stride)(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def resnet_model(input_shape=(224, 224, 3), num_classes=10):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 64, conv_shortcut=False)\n",
        "\n",
        "    x = resnet_block(x, 128, stride=2)\n",
        "    x = resnet_block(x, 128, conv_shortcut=False)\n",
        "\n",
        "    x = resnet_block(x, 256, stride=2)\n",
        "    x = resnet_block(x, 256, conv_shortcut=False)\n",
        "\n",
        "    x = resnet_block(x, 512, stride=2)\n",
        "    x = resnet_block(x, 512, conv_shortcut=False)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Create the ResNet model\n",
        "model = resnet_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Dummy data for demonstration\n",
        "X_train = np.random.rand(100, 224, 224, 3)\n",
        "Y_train = np.random.randint(0, 10, size=(100,))\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, 10)\n",
        "\n",
        "X_test = np.random.rand(20, 224, 224, 3)\n",
        "Y_test = np.random.randint(0, 10, size=(20,))\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, 10)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "data_gen_args = dict(rotation_range=20,\n",
        "                     width_shift_range=0.2,\n",
        "                     height_shift_range=0.2,\n",
        "                     shear_range=0.2,\n",
        "                     zoom_range=0.2,\n",
        "                     horizontal_flip=True,\n",
        "                     fill_mode='nearest')\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = image_datagen.flow(X_train, Y_train, batch_size=32)\n",
        "test_generator = image_datagen.flow(X_test, Y_test, batch_size=32)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=len(X_train) // 32, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_generator)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68be8-i3FxJm"
      },
      "source": [
        "VGGNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ZOfgDIF0tP",
        "outputId": "12d90c57-9838-4064-8541-57031a598c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "782/782 [==============================] - 6148s 8s/step - loss: 2.3030 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "138/782 [====>.........................] - ETA: 1:20:57 - loss: 2.3027 - accuracy: 0.0986"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "def vgg_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices (one-hot encoding)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "# Create the VGG model\n",
        "model = vgg_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "predictions = model.predict(X_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOND60fv1qNMo8m9M0ZkdA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}