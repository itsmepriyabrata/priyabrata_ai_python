{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmTJnGsx8KS7NOjAGoq6zn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmepriyabrata/priyabrata_ai_python/blob/main/Computer_Vision_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RetinaNet"
      ],
      "metadata": {
        "id": "bhlkdGj0vONX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import preprocess_image, resize_image\n",
        "\n",
        "model_path = 'path/to/your/retinanet/model.h5'\n",
        "model = load_model(model_path, compile=False)\n",
        "\n",
        "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "              'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "              'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "              'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "              'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "              'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake']\n",
        "\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "image = preprocess_image(image)\n",
        "image, scale = resize_image(image)\n",
        "\n",
        "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "\n",
        "for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "    if score < 0.5:\n",
        "        break\n",
        "\n",
        "    color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "    x1, y1, x2, y2 = [int(x) for x in box]\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
        "    cv2.putText(image, class_names[label], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
        "\n",
        "cv2.imshow('RetinaNet Object Detection', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ToOAHRBtvZW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCN"
      ],
      "metadata": {
        "id": "EDtOfUgGvjW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "model_path = 'path/to/your/fcn/model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "class_names = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
        "              'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
        "              'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep',\n",
        "              'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = load_img(image_path)\n",
        "\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "segmentation_map = model.predict(image)[0]\n",
        "\n",
        "segmentation_map = cv2.resize(segmentation_map, (image.shape[2], image.shape[1]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "color_map = np.zeros((segmentation_map.shape[0], segmentation_map.shape[1], 3), dtype=np.uint8)\n",
        "for class_id in range(len(class_names)):\n",
        "    color = [int(c) for c in np.random.randint(0, 255, size=3)]\n",
        "    color_map[segmentation_map == class_id] = color\n",
        "\n",
        "blended_image = cv2.addWeighted(np.uint8(image[0]), 0.5, color_map, 0.5, 0)\n",
        "\n",
        "cv2.imshow('FCN Semantic Segmentation', blended_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Lw2oUjZdv3_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN"
      ],
      "metadata": {
        "id": "HmCP4UDRwPn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7*7*128, input_dim=latent_dim))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(1, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "latent_dim = 100\n",
        "input_shape = (28, 28, 1)\n",
        "epochs = 10000\n",
        "batch_size = 128\n",
        "\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(input_shape)\n",
        "gan = build_gan(generator, discriminator)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    fake_images = generator.predict(noise)\n",
        "    real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
        "    X = np.concatenate((real_images, fake_images))\n",
        "    y_real = np.ones((batch_size, 1))\n",
        "    y_fake = np.zeros((batch_size, 1))\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, y_real)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_images, y_fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    y_gan = np.ones((batch_size, 1))\n",
        "    g_loss = gan.train_on_batch(noise, y_gan)\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'Epoch: {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}')\n",
        "\n",
        "noise = np.random.normal(0, 1, (25, latent_dim))\n",
        "generated_images = generator.predict(noise)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rMKvgVfJwfje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}